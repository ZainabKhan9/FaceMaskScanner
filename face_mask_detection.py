# -*- coding: utf-8 -*-
"""face_mask_detection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16h3TNy1dI-l1eByygbQaHYmRpa0K1_R8

<a href="https://colab.research.google.com/github/sidharth178/Face-Mask-Detection-and-Alert-System/blob/master/face_mask_detection.ipynb" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a>

<h1 align ="center"><b>=========== Face Mask Detection & Alert System ===========</h1>

# **Table of Contents**

1. Introduction
1. Fetch datasets from kaggle
1. Load Dataset
1. Import library
1. Data Augmentation
1. Model Building
1. Model Fitting
1. Training Loss & Accuracy Visualization
1. Find prediction

# **Introduction**
### **Objective**
The objective of this project is to detect the presence of a face mask on human faces on live streaming video as well as on images and alert the authority to take action on those who'r not wearing mask.
### **Dataset**
Click [here](https://www.kaggle.com/prithwirajmitra/covid-face-mask-detection-dataset) to download the dataset.

The use of several datasets was necessary to collect different scenarios:
- People of different racial and ethnicities
- Masks of different types
- Masks in different positions
- Different Angles

<img align="center" src="https://miro.medium.com/max/875/1*MthYaQRvLAFJQqk65NcIsw.jpeg" width="30%" align="center"/>

# **1. Fetch datasets from kaggle**
"""

# Step-1: create .kaggle directory
import os

# Create the .kaggle folder in user's home directory if it doesn't exist
os.makedirs(os.path.expanduser("~/.kaggle"), exist_ok=True)


from google.colab import files
files.upload()  # Upload your kaggle.json here

import shutil

# Move kaggle.json to ~/.kaggle
shutil.copy("kaggle.json", os.path.expanduser("~/.kaggle/kaggle.json"))

# Set permission (optional, doesn't apply on Windows but safe to keep)
os.chmod(os.path.expanduser("~/.kaggle/kaggle.json"), 0o600)


from kaggle.api.kaggle_api_extended import KaggleApi

api = KaggleApi()
api.authenticate()

!chmod 600 ~/.kaggle/kaggle.json

# Step-4: Download datasets from kaggle using API
# !kaggle datasets download -d ashishjangra27/face-mask-12k-images-dataset
!kaggle datasets download -d prithwirajmitra/covid-face-mask-detection-dataset

"""# **2. Load Dataset**"""

# unzip the dataset
from zipfile import ZipFile
zf = ZipFile('/content/covid-face-mask-detection-dataset.zip')
zf.extractall('/content/sample_data') #save files in selected folder
zf.close()

"""# **3. Import Libraries**"""

import os
import cv2
import numpy as np
import random
import keras
from imutils import paths
import matplotlib.pyplot as plt
import seaborn as sns
from collections import Counter
from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img
from tensorflow.keras.applications.mobilenet_v2 import preprocess_input
from tensorflow.keras.preprocessing.image import img_to_array
from tensorflow.keras.utils import to_categorical

from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.layers import (Input, AveragePooling2D, Dropout,
                                     BatchNormalization, MaxPooling2D,
                                     Flatten, Dense)
from tensorflow.keras.models import Model, Sequential
from tensorflow.keras.optimizers import Adam

from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau
from sklearn.preprocessing import LabelBinarizer
from sklearn.metrics import classification_report

from zipfile import ZipFile

# Load the zip again to keep zf context
zf = ZipFile('/content/covid-face-mask-detection-dataset.zip')

# Get list of all files
file_list = zf.namelist()
print("Total files in zip:", len(file_list))

# Preview top and bottom (head & tail)
print("\nðŸ“„ Head:")
print("\n".join(file_list[:5]))

print("\nðŸ“„ Tail:")
print("\n".join(file_list[-5:]))

from collections import defaultdict

class_counts = defaultdict(int)

for f in image_files:
    parts = f.split('/')
    if len(parts) > 1:
        label = parts[-2]
        class_counts[label] += 1

print("Images per class:")
for label, count in class_counts.items():
    print(f"{label:20}: {count}")

"""Display sample images from zip"""

import matplotlib.pyplot as plt
from PIL import Image
import io

def show_images_from_zip(zf, file_list, n=5):
    plt.figure(figsize=(15, 3))
    for i in range(n):
        file = file_list[i]
        data = zf.read(file)
        img = Image.open(io.BytesIO(data)).convert("RGB")
        plt.subplot(1, n, i+1)
        plt.imshow(img)
        plt.title(file.split('/')[-2])
        plt.axis('off')
    plt.show()

show_images_from_zip(zf, image_files)

image_shapes = []

for f in image_files[:200]:  # sample 200 images
    data = zf.read(f)
    try:
        img = Image.open(io.BytesIO(data)).convert("RGB")
        image_shapes.append(img.size)  # (width, height)
    except:
        continue

# Analyze dimensions
import numpy as np
widths, heights = zip(*image_shapes)
print("Avg Width:", np.mean(widths))
print("Avg Height:", np.mean(heights))
print("Min Width:", min(widths), "Max Width:", max(widths))
print("Min Height:", min(heights), "Max Height:", max(heights))

import os
import cv2
import numpy as np
import random
import keras

from imutils import paths
import matplotlib.pyplot as plt
from tensorflow.keras.applications.mobilenet_v2 import preprocess_input
from tensorflow.keras.preprocessing.image import img_to_array
from keras.preprocessing.image import ImageDataGenerator, load_img
from tensorflow.keras.utils import to_categorical
from sklearn.preprocessing import LabelBinarizer

from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.layers import Input
from tensorflow.keras.layers import AveragePooling2D
from tensorflow.keras.layers import Dropout,BatchNormalization,MaxPooling2D
from tensorflow.keras.layers import Flatten
from tensorflow.keras.layers import Dense
from tensorflow.keras.layers import Input
from tensorflow.keras import Sequential
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam

from keras.callbacks import ModelCheckpoint
from keras.callbacks import EarlyStopping, ReduceLROnPlateau
from sklearn.metrics import classification_report

"""# **4. Sample Image**
### **With Mask**
"""

images_withMask = os.listdir("/content/sample_data/New Masks Dataset/Train/Mask")
sample_img_withMask = random.choice(images_withMask)
image = load_img("/content/sample_data/New Masks Dataset/Train/Mask/"+sample_img_withMask)
plt.imshow(image)

"""### **Without Mask**"""

images_withoutMask = os.listdir("/content/sample_data/New Masks Dataset/Train/Non Mask")
sample_img_withoutMask = random.choice(images_withoutMask)
image = load_img("/content/sample_data/New Masks Dataset/Train/Non Mask/"+sample_img_withoutMask)
plt.imshow(image)

"""# **5. Data Augmentation**"""

# define constant
img_width=224
img_height=224

# initialize the initial learning rate, number of epochs to train for, and batch size
INIT_LR = 1e-4
EPOCHS = 50
BS = 32
train_data_dir="/content/sample_data/New Masks Dataset/Train"
test_data_dir="/content/sample_data/New Masks Dataset/Validation"

all_train_imagePaths = list(paths.list_images(train_data_dir))
all_test_imagePaths = list(paths.list_images(test_data_dir))
train_data = []
train_labels = []
test_data = []
test_labels = []

# loop over the image paths
for imagePath in all_train_imagePaths:
	# extract the class label from the filename
	label = imagePath.split(os.path.sep)[-2]

	# load the input image (224x224) and preprocess it
	image = load_img(imagePath, target_size=(224, 224))
	image = img_to_array(image)
	image = preprocess_input(image)

	# update the data and labels lists, respectively
	train_data.append(image)
	train_labels.append(label)

# loop over the image paths
for imagePath in all_test_imagePaths:
	# extract the class label from the filename
	label = imagePath.split(os.path.sep)[-2]

	# load the input image (224x224) and preprocess it
	image = load_img(imagePath, target_size=(224, 224))

	image = img_to_array(image)
	image = preprocess_input(image)

	# update the data and labels lists, respectively
	test_data.append(image)
	test_labels.append(label)

def convert_data_labels(data,labels):
  # convert the data and labels to NumPy arrays
  data = np.array(data, dtype="float32")
  labels = np.array(labels)

  # perform one-hot encoding on the labels
  lb = LabelBinarizer()
  labels = lb.fit_transform(labels)
  labels = to_categorical(labels)
  return  data,labels

train_data,train_labels = convert_data_labels(train_data,train_labels)
test_data,test_labels = convert_data_labels(test_data,test_labels)

print("==================================")
print("Size of train dataset : ",train_data.shape[0])
print("==================================")
print("Size of test dataset : ",test_data.shape[0])
print("==================================")

# train datagen
train_datagen = ImageDataGenerator(
                  rotation_range=20,
                  zoom_range=0.15,
                  width_shift_range=0.2,
                  height_shift_range=0.2,
                  shear_range=0.15,
                  horizontal_flip=True,
                  fill_mode="nearest")

train_generator = train_datagen.flow(train_data, train_labels, batch_size=BS)

"""# **6. Model Building**

### **6.1. Load MobileNetV2**
"""

# load the MobileNetV2 network, ensuring the head FC layer sets are left off
mobilenet = MobileNetV2(weights="imagenet", include_top=False, input_tensor=Input(shape=(224, 224, 3)))

# construct the head of the model that will be placed on top of the the base model
headModel = mobilenet.output
headModel = AveragePooling2D(pool_size=(7, 7))(headModel)
headModel = Flatten(name="flatten")(headModel)
headModel = Dense(128, activation="relu")(headModel)
headModel = Dropout(0.5)(headModel)
headModel = Dense(2, activation="softmax")(headModel)

# place the head FC model on top of the base model (this will become the actual model we will train)
model = Model(inputs=mobilenet.input, outputs=headModel)

# compile our model
print("[INFO] compiling model...")
opt = Adam(learning_rate=INIT_LR, decay=INIT_LR / EPOCHS)
model.compile(loss="binary_crossentropy", optimizer=opt,metrics=["accuracy"])
print("Done !!")

# loop over all layers in the base model and freeze them so they will *not* be updated during the first training process
for layer in mobilenet.layers:
	layer.trainable = False

# this code is to show how much time required to train the model using different algorithms
from datetime import datetime
def timer(start_time= None):
  if not start_time:
    start_time=datetime.now()
    return start_time
  elif start_time:
    thour,temp_sec=divmod((datetime.now()-start_time).total_seconds(),3600)
    tmin,tsec=divmod(temp_sec,60)
    print('\n Time taken: %i hours %i minutes and %s seconds. '% (thour,tmin,round(tsec,2)))

"""### **6.2. Callback Function**"""

# checkpoint = ModelCheckpoint('model-{epoch:03d}.model',monitor='val_loss',verbose=0,save_best_only=True,mode='auto')
# # history=model.fit(train_data,train_target,epochs=100,callbacks=[checkpoint],validation_split=0.2)
# EarlyStopping
earlystop = EarlyStopping(monitor = 'val_loss',
                          min_delta = 0,
                          patience = 7,
                          verbose = 1,
                          restore_best_weights = True)

# ModelCheckPoint
checkPoint = keras.callbacks.ModelCheckpoint(filepath="/content/sample_data/fmd_model.h5",
                             monitor='val_loss',
                             mode='auto',
                             save_best_only=True,
                             verbose=1)

# ReduceLROnPlateau
learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy',
                                            patience=2,
                                            verbose=1,
                                            factor=0.5,
                                            min_lr=0.00001)

# TBoard = tf.keras.callbacks.TensorBoard(log_dir='./logs')

callbacks = [earlystop , checkPoint, learning_rate_reduction]

"""# **7. Model Fitting**"""

start_time=timer(None)
classifier = model.fit(
    train_datagen.flow(train_data, train_labels, batch_size=BS),
    epochs=EPOCHS,
    validation_data=(test_data,test_labels),
    validation_steps=len(test_data)//BS,
    steps_per_epoch=len(train_data)//BS,
    callbacks=callbacks
)
timer(start_time)

from google.colab import drive
drive.mount('/content/drive')

model_path = '/content/drive/MyDrive/face_mask_model.h5'
model.save(model_path)
print(f"âœ… Model saved at: {model_path}")

"""# **8. Training Loss and Accuracy Visualization**"""

# plot the training loss and accuracy
plt.style.use("ggplot")
N = 10 # epochs number
plt.figure()
plt.plot( classifier.history["loss"], label="train_loss")
plt.plot( classifier.history["val_loss"], label="val_loss")
plt.plot( classifier.history["accuracy"], label="train_acc")
plt.plot( classifier.history["val_accuracy"], label="val_acc")
plt.title("Training Loss and Accuracy")
plt.xlabel("Epoch #")
plt.ylabel("Loss/Accuracy")
plt.legend(loc="center right")
plt.savefig("CNN_Model")

"""### **8.1. Find Prediction**"""

# make predictions on the testing set
print("[INFO] evaluating network...")
predIdxs = model.predict(test_data, batch_size=BS)

# for each image in the testing set we need to find the index of the
# label with corresponding largest predicted probability
predIdxs = np.argmax(predIdxs, axis=1)

"""### **8.2. Find Accuracy**"""

# check accuracy
val_loss,val_acc = model.evaluate(test_data,test_labels)
print("=======================================================")
print("Accuracy is : ",val_acc)
print("=======================================================")
print("Loss is : ",val_loss)
print("=======================================================")

"""### **8.3. Classification Report**"""

# show a nicely formatted classification report
print(classification_report(test_labels.argmax(axis=1), predIdxs))

# Mount Drive & Save
from google.colab import drive
drive.mount('/content/drive')

model_path = '/content/drive/MyDrive/face_mask_model.h5'
model.save(model_path)
print(f"âœ… Model saved at: {model_path}")

