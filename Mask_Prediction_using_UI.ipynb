{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# STEP 1: Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P6MNWRqOd3Qi",
        "outputId": "060fc790-dff3-48e4-bedd-054dcfa615ab"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# STEP 1: Install Required Libraries\n",
        "!pip install gradio tensorflow --quiet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Olid3_LpeI32",
        "outputId": "407dfd6b-de78-4aba-f4e5-d2dc9bd258e5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.9/46.9 MB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.2/322.2 kB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m99.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# STEP 2: Import Libraries\n",
        "import gradio as gr\n",
        "import cv2\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input"
      ],
      "metadata": {
        "id": "2d21qpKheOQo"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0zoSR8MYd0AX",
        "outputId": "f42b4774-c706-495c-90ef-6c8e33ba704c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "\n",
        "# STEP 3: Load your saved model (e.g. from Google Drive)\n",
        "model = load_model('/content/drive/MyDrive/face_mask_model.h5')\n",
        "class_names = [\"Mask\", \"No Mask\"]\n",
        "\n",
        "# STEP 4: Define a prediction function\n",
        "# Prediction function\n",
        "def predict_mask(image):\n",
        "    try:\n",
        "        image_resized = cv2.resize(image, (224, 224))\n",
        "        image_rgb = cv2.cvtColor(image_resized, cv2.COLOR_BGR2RGB)\n",
        "        image_array = preprocess_input(np.array(image_rgb))\n",
        "        image_array = np.expand_dims(image_array, axis=0)\n",
        "\n",
        "        preds = model.predict(image_array)[0]\n",
        "        print(\"Raw predictions:\", preds)\n",
        "\n",
        "        label = class_names[np.argmax(preds)]\n",
        "        confidence = np.max(preds) * 100\n",
        "\n",
        "        result_text = f\"🧠 Prediction: {label} ({confidence:.2f}%)\"\n",
        "        return result_text\n",
        "    except Exception as e:\n",
        "        return f\"Error: {str(e)}\"\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Create interface\n",
        "with gr.Blocks(theme=gr.themes.Base()) as demo:\n",
        "    gr.Markdown(\"## 😷 Face Mask Detector\")\n",
        "    gr.Markdown(\"Upload a face image to detect if the person is wearing a mask or not.\")\n",
        "\n",
        "    with gr.Row():\n",
        "        input_image = gr.Image(type=\"numpy\", label=\"Upload a Face Image\")\n",
        "        output_text = gr.Textbox(label=\"Prediction\")\n",
        "\n",
        "    submit_btn = gr.Button(\"Submit\")\n",
        "\n",
        "    submit_btn.click(fn=predict_mask, inputs=input_image, outputs=output_text)\n",
        "\n",
        "# Launch without flagging or footer\n",
        "demo.launch(show_api=False, share=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 614
        },
        "id": "j8ny0fdmeR9i",
        "outputId": "49f574b6-9294-4e83-f581-74f700cd3a86"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://d31562cdeee7b6dfb3.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://d31562cdeee7b6dfb3.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "onGxOamIeS0H"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}